{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import json\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self) -> None:\n",
    "        openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=\"text-embedding-3-large\"\n",
    "        )\n",
    "        self.client = chromadb.Client(Settings(persist_directory=\"./\"))\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            \"feature_store\", embedding_function=openai_ef\n",
    "        )\n",
    "        self.client = chromadb.PersistentClient(path=\"./\")\n",
    "\n",
    "\n",
    "    def get_entry_numbers(self):\n",
    "        number_of_entries = self.collection.count()\n",
    "        return number_of_entries\n",
    "\n",
    "    def add(self, text, time):\n",
    "        number_of_entries = self.get_entry_numbers()\n",
    "        self.collection.add(\n",
    "            documents=[\n",
    "                str(text)\n",
    "            ],  # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "            metadatas=[{\"timestamp\":time}],  # filter on these!\n",
    "            ids=[str(number_of_entries)],  # unique for each document\n",
    "        )\n",
    "\n",
    "    def retrieve(self, query, n=2, time_field=None):\n",
    "        if time_field is not None:\n",
    "            results = self.collection.query(\n",
    "                query_texts=query,\n",
    "                n_results=n,\n",
    "                where={\"timestamp\": time_field}, # optional filter\n",
    "            )\n",
    "        elif time_field is None:\n",
    "            results = self.collection.query(\n",
    "                query_texts=query,\n",
    "                n_results=n,\n",
    "            )\n",
    "        return results\n",
    "\n",
    "    def injest_chunks(self, chunks, timestamp):\n",
    "        for chunk, time in zip(chunks, timestamp):\n",
    "            self.add(chunk, time)\n",
    "\n",
    "    def get_start_time(self, text):\n",
    "        segments = text.split(\"|\")\n",
    "        start_time_segment = segments[0].split(\":\")[1]\n",
    "        start_time = float(start_time_segment)\n",
    "        return int(start_time)\n",
    "\n",
    "    def extract_text_blocks(self, txt_file_path, n):\n",
    "        text_blocks = []\n",
    "        timestamp = []\n",
    "        chunk = \"\"\n",
    "        with open(txt_file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            largest_index_div_by_n = (len(lines)//n)*n\n",
    "            largest_index = len(lines)\n",
    "            for idx, line in enumerate(lines):\n",
    "                text_part = line.split(\"text:\")[1].strip()\n",
    "                chunk += text_part + \" \"\n",
    "\n",
    "                if idx % n == 2:\n",
    "                    text_blocks.append(chunk)\n",
    "                    timestamp.append(time_part)\n",
    "                    chunk = \"\"\n",
    "                elif idx % n == 0:\n",
    "                    time_part = self.get_start_time(line)\n",
    "\n",
    "                if idx == largest_index:\n",
    "                    text_blocks.append(chunk)\n",
    "                    timestamp.append(time_part)\n",
    "        return text_blocks, timestamp\n",
    "\n",
    "    def extract_text(self, line):\n",
    "        text = line.split(\"|\")[-1]\n",
    "        text = text.split(\"text:\")[-1].strip()\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_single_timestamp\",\n",
    "                \"description\": \"Get the description of a conversation at a specific timestamp\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"time\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The timestamp to get the description for in dd/mm/yyyy hh:mm:ss format\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"time\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_start_end_timestamp\",\n",
    "                \"description\": \"Get the start and end timestamp of a conversation\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"start_time\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the start time mentioned provided in dd/mm/yyyy hh:mm:ss format\",\n",
    "                        },\n",
    "                        \"end_time\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"End time mentioned provided in dd/mm/yyyy hh:mm:ss format\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"start_time\", \"end_time\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_topic\",\n",
    "                \"description\": \"Get the topic of the conversation\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"topic\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The topic of conversation\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"topic\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "    @retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "    def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=tool_choice,\n",
    "                seed =123,\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(\"Unable to generate ChatCompletion response\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            return e\n",
    "        \n",
    "    def run(prompt):\n",
    "        current_datetime = datetime.now()\n",
    "        formatted_date = current_datetime.strftime(\"%d/%m/%Y\")\n",
    "        print(formatted_date)\n",
    "        messages = []\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\",\n",
    "            }\n",
    "        )\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": f\"For reference today is {formatted_date}\"})\n",
    "        chat_response = Retriever.chat_completion_request(messages, tools=Retriever.tools)\n",
    "        assistant_message = chat_response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        fn_name=assistant_message.tool_calls[0].function.name\n",
    "        args=json.loads(assistant_message.tool_calls[0].function.arguments)\n",
    "        print(args)\n",
    "        print(fn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 195\n"
     ]
    }
   ],
   "source": [
    "text_file = \"./text/sharktank.txt\"\n",
    "store = VectorStore()\n",
    "chunks, timestamp = store.extract_text_blocks(txt_file_path=text_file, n=3)\n",
    "print(len(chunks), len(timestamp))\n",
    "store.injest_chunks(chunks, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/02/2024\n",
      "{'topic': 'sandcastles'}\n",
      "get_topic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['3', '7']],\n",
       " 'distances': [[1.0464648008346558, 1.096422791481018]],\n",
       " 'metadatas': [[{'timestamp': 52}, {'timestamp': 121}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"but it's impossible to build a real sand castle using the traditional fill and flip buckets. The wet sand sticks in the bucket, even at its best, it just looks boring. That's why we invented Create-A-Castle, revolutionary split mold sand castle kits that allow you to build elaborate sand structures in no time at all. \",\n",
       "   \"Nothing like this. We're unique in the fact that we split, so the molds split in half, but they also are stackable in the right kind of sand. You built that entire castle. \"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"when did we speak about sandcastles?\"\n",
    "Retriever.run(prompt)\n",
    "store.retrieve(prompt, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
